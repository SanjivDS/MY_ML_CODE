{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist= tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_img,train_label),(test_img,test_label)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There's a bit of a change here in that the training data needed to be reshaped. \n",
    "#That's because the first convolution expects a single tensor containing everything.\n",
    "#So instead of 60,000 28x28x1 items in a list, we have a single 4D list .\n",
    "#That is 60,000x28x28x1, and the same for the test images. \n",
    "#If you don't do this, you'll get an error when training as the Convolutions do not recognize the shape.\n",
    "train_img=train_img.reshape(60000,28,28,1)\n",
    "train_img=train_img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing for the test set .\n",
    "test_img=test_img.reshape(10000,28,28,1)\n",
    "test_img=test_img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now instead of the input layer at the top, you're going to add a Convolution.\n",
    "#3*3 grid\n",
    "# MaxPooling layer which is then designed to compress the image\n",
    "# By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. \n",
    "#the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. \n",
    "#t repeats this across the image, and in so doing halves the number of horizontal.\n",
    "#And halves the number of vertical pixels, effectively reducing the image by 25%.\n",
    "model=tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary() to see the size and shape of the network\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_img, train_label, epochs=5)\n",
    "test_loss = model.evaluate(test_img, test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
